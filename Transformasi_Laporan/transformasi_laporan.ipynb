{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8be2d90d676f412a9d33ec05da48cbd1",
    "deepnote_cell_type": "code",
    "execution_context_id": "d666d593-02b7-49ad-8f1a-bb15c12776a3",
    "execution_millis": 55926,
    "execution_start": 1744965502569,
    "source_hash": "4c06952a"
   },
   "outputs": [],
   "source": [
    "#Install yang dibutuhkan\n",
    "\n",
    "!pip install pyspark python-dotenv pymongo\n",
    "# Download JARs manually or ensure they are in the classpath/working directory:\n",
    "# mongo-spark-connector_2.12-3.0.1.jar\n",
    "# mongo-java-driver-3.12.10.jar\n",
    "# Ensure you have a compatible JDK (like OpenJDK 11) installed and JAVA_HOME is set in your system environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koneksi ke MOongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Loads variables from .env file in the current working directory or parent directories\n",
    "\n",
    "# Fetch MongoDB credentials and config from environment variables\n",
    "mongo_connection_string = os.getenv(\"MONGODB_CONNECTION_STRING\")\n",
    "mongo_db_name = os.getenv(\"MONGODB_DATABASE_NAME\")\n",
    "mongo_input_collection = os.getenv(\"COLLECTION_FINANCIAL_REPORTS\")\n",
    "mongo_output_collection = \"Transformasi_LaporanKeuangan\" # Specific collection for this script's output\n",
    "\n",
    "# Construct the input URI\n",
    "mongo_input_uri = mongo_connection_string # Use base connection string\n",
    "mongo_output_uri = mongo_connection_string # Use base connection string for output as well\n",
    "\n",
    "if not all([mongo_connection_string, mongo_db_name, mongo_input_collection]):\n",
    "    raise ValueError(\"One or more MongoDB environment variables are missing. Check your .env file.\")\n",
    "\n",
    "print(f\"Using Database: {mongo_db_name}\")\n",
    "print(f\"Input Collection: {mongo_input_collection}\")\n",
    "print(f\"Output Collection: {mongo_output_collection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrasi pyspark\n",
    "\n",
    "Jika Masih bermasalah maka harus melakukan beberapa langkah instalasi terlebih dahulu dari output cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5bfbbd0652e446e5b73bc4e2e2596f96",
    "deepnote_cell_type": "code",
    "execution_context_id": "d666d593-02b7-49ad-8f1a-bb15c12776a3",
    "execution_millis": 4871,
    "execution_start": 1744965571543,
    "source_hash": "5b063ae1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set JAVA_HOME if not set globally (adjust path if necessary for your Windows setup)\n",
    "if \"JAVA_HOME\" not in os.environ:\n",
    "    print(\"Warning: JAVA_HOME environment variable not set. Spark might not work correctly.\")\n",
    "\n",
    "# Gabungkan semua JAR jadi satu string (ensure these files are in the current dir or provide full paths)\n",
    "jars_path = \".\" # Assumes JARs are in the same directory as the notebook\n",
    "jars = \",\".join([\n",
    "    os.path.join(jars_path, \"mongo-spark-connector_2.12-3.0.1.jar\"),\n",
    "    os.path.join(jars_path, \"mongo-java-driver-3.12.10.jar\")\n",
    "])\n",
    "\n",
    "# Check if JAR files exist\n",
    "for jar_file in jars.split(','):\n",
    "    if not os.path.exists(jar_file):\n",
    "        print(f\"Warning: JAR file not found at {jar_file}. Download it or update the path.\")\n",
    "\n",
    "# Build SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MongoDBSparkTransform\") \\\n",
    "    .config(\"spark.jars\", jars) \\\n",
    "    .config(\"spark.mongodb.input.uri\", mongo_input_uri) \\\n",
    "    .config(\"spark.mongodb.input.database\", mongo_db_name) \\\n",
    "    .config(\"spark.mongodb.input.collection\", mongo_input_collection) \\\n",
    "    .config(\"spark.mongodb.output.uri\", mongo_output_uri) \\\n",
    "    .config(\"spark.mongodb.output.database\", mongo_db_name) \\\n",
    "    .config(\"spark.mongodb.output.collection\", mongo_output_collection) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "29be436ca8d0412f8f299b50a577e657",
    "deepnote_cell_type": "code",
    "execution_context_id": "d666d593-02b7-49ad-8f1a-bb15c12776a3",
    "execution_millis": 80293,
    "execution_start": 1744965678560,
    "source_hash": "d92e6872"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, lit, coalesce\n",
    "\n",
    "# Step 1: Load data from MongoDB using SparkSession config\n",
    "spark.conf.set(\"spark.sql.caseSensitive\", True)\n",
    "\n",
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "\n",
    "# Step 2: schema yang akan digunakan\n",
    "schema = StructType([\n",
    "    StructField(\"EntityName\", StringType(), True),\n",
    "    StructField(\"EntityCode\", StringType(), True),\n",
    "    StructField(\"SalesAndRevenue\", DoubleType(), True),\n",
    "    StructField(\"GrossProfit\", DoubleType(), True),\n",
    "    StructField(\"ProfitFromOperation\", DoubleType(), True),\n",
    "    StructField(\"ProfitLoss\", DoubleType(), True),\n",
    "    StructField(\"CashAndCashEquivalents\", DoubleType(), True),\n",
    "    StructField(\"Assets\", DoubleType(), True),\n",
    "    StructField(\"ShortTermBankLoans\", DoubleType(), True),\n",
    "    StructField(\"LongTermBankLoans\", DoubleType(), True),\n",
    "    StructField(\"EquityAttributableToEquityOwnersOfParentEntity\", DoubleType(), True),\n",
    "    StructField(\"NetCashFlowOp\", DoubleType(), True),\n",
    "    StructField(\"NetCashFlowInv\", DoubleType(), True),\n",
    "    StructField(\"NetCashFlowFin\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Step 3: mengambil kolom dari MongoDB\n",
    "df_selected = df.withColumn(\"EntityName\", col(\"xbrl_data.EntityName\")) \\\n",
    "    .withColumn(\"EntityCode\", col(\"xbrl_data.EntityCode\")) \\\n",
    "    .withColumn(\"SalesAndRevenue\", col(\"xbrl_data.SalesAndRevenue\").cast(DoubleType())) \\\n",
    "    .withColumn(\"GrossProfit\", col(\"xbrl_data.GrossProfit\").cast(DoubleType())) \\\n",
    "    .withColumn(\"ProfitFromOperation\", col(\"xbrl_data.ProfitFromOperation\").cast(DoubleType())) \\\n",
    "    .withColumn(\"ProfitLoss\", col(\"xbrl_data.ProfitLoss\").cast(DoubleType())) \\\n",
    "    .withColumn(\"CashAndCashEquivalents\", col(\"xbrl_data.CashAndCashEquivalents\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Assets\", col(\"xbrl_data.Assets\").cast(DoubleType())) \\\n",
    "    .withColumn(\"ShortTermBankLoans\", col(\"xbrl_data.ShortTermBankLoans\").cast(DoubleType())) \\\n",
    "    .withColumn(\"LongTermBankLoans\", col(\"xbrl_data.LongTermBankLoans\").cast(DoubleType())) \\\n",
    "    .withColumn(\"EquityAttributableToEquityOwnersOfParentEntity\", \n",
    "               col(\"xbrl_data.EquityAttributableToEquityOwnersOfParentEntity\").cast(DoubleType())) \\\n",
    "    .withColumn(\"NetCashFlowOp\", \n",
    "               col(\"xbrl_data.NetCashFlowsReceivedFromUsedInOperatingActivities\").cast(DoubleType())) \\\n",
    "    .withColumn(\"NetCashFlowInv\", \n",
    "               col(\"xbrl_data.NetCashFlowsReceivedFromUsedInInvestingActivities\").cast(DoubleType())) \\\n",
    "    .withColumn(\"NetCashFlowFin\", \n",
    "               col(\"xbrl_data.NetCashFlowsReceivedFromUsedInFinancingActivities\").cast(DoubleType()))\n",
    "\n",
    "# Step 4: menambahkan kolom null untuk kolom yang tidak ada\n",
    "for field in schema:\n",
    "    if field.name not in df_selected.columns:\n",
    "        df_selected = df_selected.withColumn(field.name, lit(None).cast(field.dataType))\n",
    "\n",
    "# Step 5: Drop kolom yang tidak diperlukan\n",
    "df_final = df_selected.select(schema.fieldNames())\n",
    "\n",
    "# Step 6: (Optional) Save to local JSON if needed\n",
    "# output_path = \"terstrukturrr\"\n",
    "# df_final.write.mode(\"overwrite\") \\\n",
    "#     .option(\"ignoreNullFields\", \"false\") \\\n",
    "#     .json(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "573b067dc6fc4ababd10275ce9602b20",
    "deepnote_cell_type": "code",
    "execution_context_id": "d666d593-02b7-49ad-8f1a-bb15c12776a3",
    "execution_millis": 19290,
    "execution_start": 1744965766839,
    "source_hash": "4e0e36f2"
   },
   "outputs": [],
   "source": [
    "# Fill nulls before showing or writing\n",
    "df_final = df_final.na.fill(0)\n",
    "df_final.printSchema() # Good practice to check schema before writing\n",
    "df_final.show(5) # Show a few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload ke MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c06e547b06814019a0baa64d8afc8a93",
    "deepnote_cell_type": "code",
    "execution_context_id": "48fecaaa-460b-49ff-b079-2ce7fcfc3c68",
    "execution_millis": 21434,
    "execution_start": 1744962838864,
    "source_hash": "8c04154b"
   },
   "outputs": [],
   "source": [
    "# Upload ke MongoDB collection baru using SparkSession config\n",
    "# The output URI, database, and collection are already configured in the SparkSession\n",
    "df_final.write \\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"ignoreNullFields\", \"false\") \\\n",
    "    .save()\n",
    "\n",
    "print(f\"Data successfully written to MongoDB database '{mongo_db_name}', collection '{mongo_output_collection}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=88872151-d0a6-473f-a5ae-6bcca9563221' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "2145084af3b7444999bc507228df97f5",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
